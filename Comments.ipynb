{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cb943d",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9132bb",
   "metadata": {},
   "source": [
    "**Краткая суть**\n",
    "\n",
    "Необходимо обучить модель классифицировать комментарии на позитивные и негативные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174a62d",
   "metadata": {},
   "source": [
    "**Описание**\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис, где пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34ee18",
   "metadata": {},
   "source": [
    "**Критерии оценки модели**\n",
    "\n",
    "* Значение метрики F1 на тестовой выборке должно быть не меньше 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893a88b",
   "metadata": {},
   "source": [
    "**План выполнения проекта**\n",
    "\n",
    "1. Загрузить и подготовьть данные.\n",
    "2. Обучить разные модели.\n",
    "3. Сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f2519",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43b8ae",
   "metadata": {},
   "source": [
    "### Загрузим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c337e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c9b36",
   "metadata": {},
   "source": [
    "### Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3666f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual = '/datasets/toxic_comments.csv'\n",
    "local = '/file_for_projects/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(virtual):\n",
    "    df = pd.read_csv(virtual)\n",
    "elif os.path.exists(local):\n",
    "    df = pd.read_csv(local)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69de4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(data):\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Информация о файле')\n",
    "    print('')\n",
    "    df.info()\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Первые 5 строк файла')\n",
    "    display(df.head())\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Количество пропусков')\n",
    "    display(df.isna().sum())\n",
    "    print('')\n",
    "    print('')\n",
    "    print('Количество дубликатов')\n",
    "    display(df.index.duplicated().sum())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de76a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Информация о файле\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "\n",
      "\n",
      "Первые 5 строк файла\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Количество пропусков\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Количество дубликатов\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "check_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b1ee0",
   "metadata": {},
   "source": [
    "**У нас есть датафрейм в котором 159292 строки и 3 столбца. В столбце text содержится комментарий (на английском языке), столбец toxic целевой, в нем 0 означает \"комментарий не токсичный\", а 1 говорит о том, что комментарий токсичный. От стообца Unnamed избавимся.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8fee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa83144",
   "metadata": {},
   "source": [
    "### Посмотрим на распределение комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7941d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586ae89",
   "metadata": {},
   "source": [
    "**Мы наблюдаем дисбаланс классв, не токсичных в 10 раз больше. Посмотрим какими получатся метрики, и если значение не будет нас удовлетворять, будем решать что делать с этим.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedb04e",
   "metadata": {},
   "source": [
    "### Посмотрим качество разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bdee9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I said that it's a mix of the various bits, anyway, I'm sure we'll email back and fourth a few times before I get permission, so I'll tell then if they specifically ask. However, I feel that it's still fair use. (talk|email)\n",
      "\"\n",
      "\n",
      " NintendoLife Retrospective \n",
      "\n",
      " http://www.nintendolife.com/news/2015/06/matters_of_import_fire_emblem_sort_of_exists_on_the_sony_playstation \n",
      "\n",
      "While I can't help but notice that they decided to do a retrospective just a little after I've completely rewritten the article (and cover most of the same points), but it can still offer some new info to the article, mostly reception-related content.  msg me \"\n",
      "Invitation to a Wicnic in Gainesville on Saturday, June 22nd \n",
      "\n",
      "Greetings!\n",
      "\n",
      "Seeing that you're a member of WikiProject University of Florida, I'm inviting to the North Central Florida 2013 Great American Wiknic that will be on Saturday June 22, 2013, commencing at 1:00 pm, ten blocks north of UF campus in Gainesville,.\n",
      "\n",
      "If you're able and inclined to come, please RSVP at at this URL.\n",
      "\n",
      "Type to you later,\n",
      "\"\n",
      "Hi! Dimitrov has published stories for children. Biographical note in his book \"\"The name and the mind\"\" (Skopje 1999) referred to three separate editions with stories for children - \"\"Shepherd boy\"\", \"\"Goodbye childhood\"\" and \"\"Where we are  children\"\". Regards,   \"\n",
      "\"\n",
      "\n",
      " B-class \n",
      "\n",
      "Passed for WP:POLAND. | reply here \"\n",
      "Russian \n",
      "I gave you several sources that say that millions of people in former USSR (not just Russia) speak Russian on a native level (see Talk:Ethnologue list of languages). Methinks you are just a Russophobe, anti-Russian. Lots of that these days... So sad...\n",
      "Hi\n",
      "\n",
      "Hi, Jimbo?  How's everything in life?\n",
      "OK, I've made another slew of blocks after confirming via CU a sock on one of the ranges; that's explained in my block of Qmihai24 on his talk page. –MuZemike\n",
      "A page you started (Rusted Dagger) has been reviewed! \n",
      "\n",
      "Thanks for creating Rusted Dagger, Eraan! \n",
      "\n",
      "Wikipedia editor  just reviewed your page, and wrote this note for you:\n",
      "\n",
      "Nominated for deletion\n",
      "\n",
      "To reply, leave a comment on Jersey92's  talk page.\n",
      "\n",
      "Learn more about page curation.\n",
      "\"\n",
      "nsaum75 should be blocked from editing this and similar articles. it is clear he is zionist and only edits from that standpoint. his attempt at creating a stacked rfc with a \"\"independent\"\" closing admin being jewish is further examples of his attemp to hijack this article for the zionists.   \"\n"
     ]
    }
   ],
   "source": [
    "for i in df[df['toxic'] == 0]['text'].sample(10, random_state=22):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2980cafb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia for online losers\n",
      "\n",
      "I am being accused of vandalizing Afghanistan's article....because the accusers are all jealous of me hahahahahahahaha.  09:32, 31 October 2006\n",
      "Knock off the gosh darn vandalism! \n",
      "\n",
      "If you keep on vandalising articles as you did to Poop I'm going to warn your ass.  This is a federal offense and you know what happens in prison.  ;)  You better watch yourself or I will unleash a powerful series of warnings.  I've got like a buttload of respect around here and I don't take kindly to people who come to these places and treat it like SHIT!  DX\n",
      "Jared Loughner and the Saphir-Wolf hypothesis \n",
      "\n",
      "Dude. Loughner said that vocabulary was invented to control people's minds. That's exactly what the Saphir-Wolf hypothesis says. Don't call me libelous, irrelevant and unsourced. Jerk.\n",
      "stop being a pussbot \n",
      "\n",
      "stop being a pussbot. you are extremely biased. Wikipedia cannto tolerate users like you. stop being a shudslavpus\n",
      "Hitlers sex children \n",
      "\n",
      "Its obvious that shitler only wanted these kids for his own perverse sexual desires. I demand you change the article and if you dont then you're a fucking racist scumbag who needs to be sent to the moon with the rest of the goonbats\n",
      "\"\n",
      "\n",
      " A kitten for you! \n",
      "\n",
      "just becuz ur pussy 4 lying.\n",
      "\n",
      "  \n",
      "\"\n",
      "Jews for Jesus \n",
      "Some Jews love Jesus in a way that can't be fully described with words...\n",
      "you know, in their anus.\n",
      "Silliness\n",
      "\n",
      "You did something silly. Please don't be silly again.   05:18, 2005 Jun 9 (UTC)\n",
      "Respect is earned by respect \n",
      "\n",
      "That user IS a troll and a stalker. They are not respected and are close to being banned. Did you bother to read the inflammatory garbage that they write on wikipedia? Or are you just part of a troll posse?\n",
      "stuff you stupid editors i reckon you should leave in all the changes i make caus theyre all true\n",
      "{especially the one bout will larsen]\n",
      "\n",
      "p.s. plz dun block me\n"
     ]
    }
   ],
   "source": [
    "for i in df[df['toxic'] == 1]['text'].sample(10, random_state=22):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4c713",
   "metadata": {},
   "source": [
    "**По представленным примерам, разметка кажется хорошей. У нас все равно нет вариантов, т к разметка производилась не нами, будем верить тому, что есть.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e099592",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0759b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test = train_test_split(test, test_size=0.29, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23bec28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((111504, 2), (33929, 2), (13859, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58615716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение комментариев на обучающей выборке 0    100104\n",
      "1     11400\n",
      "Name: toxic, dtype: int64\n",
      "Распределение комментариев на валидационной выборке 0    30553\n",
      "1     3376\n",
      "Name: toxic, dtype: int64\n",
      "Распределение комментариев на тестовой выборке 0    12449\n",
      "1     1410\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Распределение комментариев на обучающей выборке', train['toxic'].value_counts())\n",
    "print(f'Распределение комментариев на валидационной выборке', valid['toxic'].value_counts())\n",
    "print(f'Распределение комментариев на тестовой выборке', test['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c53d67",
   "metadata": {},
   "source": [
    "**Закономерность \"в 10 раз\" сохранена**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c7487",
   "metadata": {},
   "source": [
    "### Проивзедем предобработку данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af8a93",
   "metadata": {},
   "source": [
    "#### Напишем функции для преобразования данных. На вход будем подавать текст, а получать токены (без окончаний, стов-слов и знаков препинания)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412005d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def change_word(sentence: str, remove_stop_words: bool = True):\n",
    "    tokens = word_tokenize(sentence, language='english') # разбиваем текст на токены\n",
    "    if remove_stop_words:\n",
    "        tokens = [i for i in tokens if i not in eng_stopwords] # удаляем стоп-слова\n",
    "    tokens = [lemmatizer.lemmatize(i) for i in tokens] # лемматизируем токены\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def clear_text(sentence: str, remove_stop_words: bool = True):  # функция для удаления знаков препинания\n",
    "    sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = sentence.split()\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2357e0",
   "metadata": {},
   "source": [
    "#### Проверим что всё работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d215497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nReliable sources indicate otherwise. Please do not insert your personal analysis into the article.  (talk) \"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[202]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17078fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reliable',\n",
       " 'source',\n",
       " 'indicate',\n",
       " 'otherwise',\n",
       " 'Please',\n",
       " 'insert',\n",
       " 'personal',\n",
       " 'analysis',\n",
       " 'article',\n",
       " 'talk']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_word(clear_text(df.iloc[202]['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bac94",
   "metadata": {},
   "source": [
    "#### Инициализируем TF-IFD векторайзер, который подготовит из текста числовую матрицу для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7302c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: change_word(clear_text(x, remove_stop_words=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28437d85",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3ec52",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e12498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipelene = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"model\", LogisticRegression(random_state=22, solver='lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d13b7fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x000002721FB15310>)),\n",
       "                ('model', LogisticRegression(random_state=22))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipelene.fit(train['text'], train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "facebff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr_pipelene.fit(train['text'], train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "970ba81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(valid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b0f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1 = f1_score(valid['toxic'], lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1abd783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     30553\n",
      "           1       0.92      0.62      0.74      3376\n",
      "\n",
      "    accuracy                           0.96     33929\n",
      "   macro avg       0.94      0.80      0.86     33929\n",
      "weighted avg       0.96      0.96      0.95     33929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid['toxic'], lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7cc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[30378   175]\n",
      " [ 1299  2077]]\n",
      "\n",
      "True Positives(TP) =  30378\n",
      "\n",
      "True Negatives(TN) =  2077\n",
      "\n",
      "False Positives(FP) =  175\n",
      "\n",
      "False Negatives(FN) =  1299\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid['toxic'], lr_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421581e",
   "metadata": {},
   "source": [
    "**Логистическая регрессия, без подбора гиперпараметров, может достаточно хорошо делить комментарии, но страдает точность. Из матрици ошибок следует, что 1299 ответов ложноотрицательные и 175 ложноположительных** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c4114",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea38d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_pipelene = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"model\", SGDClassifier(random_state=22))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08846cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = sgdc_pipelene.fit(train['text'], train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c60500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_pred = sgdc.predict(valid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "345967ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_f1 = f1_score(valid['toxic'], sgdc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80149346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     30553\n",
      "           1       0.96      0.48      0.64      3376\n",
      "\n",
      "    accuracy                           0.95     33929\n",
      "   macro avg       0.95      0.74      0.81     33929\n",
      "weighted avg       0.95      0.95      0.94     33929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid['toxic'], sgdc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f379b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[30485    68]\n",
      " [ 1750  1626]]\n",
      "\n",
      "True Positives(TP) =  30485\n",
      "\n",
      "True Negatives(TN) =  1626\n",
      "\n",
      "False Positives(FP) =  68\n",
      "\n",
      "False Negatives(FN) =  1750\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid['toxic'], sgdc_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3956a7b",
   "metadata": {},
   "source": [
    "**Модель SGDClassifier (с простой реализацией обучения стохастическим градиентным спуском) , без подбора гиперпараметров, может достаточно хорошо делить комментарии, но точность страдает еще больше. Из матрици ошибок следует, что 1750 ответов ложноотрицательные и 68 ложноположительные** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecf820",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "273d760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pipelene = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"model\", LGBMClassifier(random_state=22))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30dc7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = lgb_pipelene.fit(train['text'], train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce9285bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = lgb.predict(valid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49645d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_f1 = f1_score(valid['toxic'], lgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68c64297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     30553\n",
      "           1       0.89      0.65      0.75      3376\n",
      "\n",
      "    accuracy                           0.96     33929\n",
      "   macro avg       0.92      0.82      0.86     33929\n",
      "weighted avg       0.95      0.96      0.95     33929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid['toxic'], lgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "381b3a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[30273   280]\n",
      " [ 1180  2196]]\n",
      "\n",
      "True Positives(TP) =  30273\n",
      "\n",
      "True Negatives(TN) =  2196\n",
      "\n",
      "False Positives(FP) =  280\n",
      "\n",
      "False Negatives(FN) =  1180\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid['toxic'], lgb_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294f015",
   "metadata": {},
   "source": [
    "**Модель LGBMClassifier (на градиентном бустинге) , без подбора гиперпараметров, тоже хорошо себя демострирует, но вот точность чуть лучше, чем у предыдущих двух моделей. Из матрици ошибок следует, что 1180 ответов ложноотрицательные и 280 ложноположительные** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010f663",
   "metadata": {},
   "source": [
    "### Побдерем гиперпараметры для LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf1f3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    classifier = Pipeline(steps=[(\"vectorizer\", vectorizer),\n",
    "                                 (\"classifier\",LGBMClassifier(random_state=22))])\n",
    "\n",
    "    params = {\n",
    "        'classifier__lambda_l1': trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        'classifier__lambda_l2': trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        'classifier__num_leaves': trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        'classifier__feature_fraction': trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        'classifier__bagging_fraction': trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        'classifier__bagging_freq': trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        'classifier__min_child_samples': trial.suggest_int(\"min_child_samples\", 5, 100)\n",
    "    }\n",
    "\n",
    "    classifier.set_params(**params)\n",
    "\n",
    "    classifier.fit(train['text'], train['toxic'])\n",
    "\n",
    "    f1 = cross_val_score(classifier, valid['text'], valid['toxic'], cv=5, scoring='f1')\n",
    "\n",
    "    return  f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c49a32b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:01:43,126]\u001b[0m A new study created in memory with name: no-name-7527449e-513b-4d2c-a356-8019f439f728\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6483993578956935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6483993578956935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6404334844550104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6404334844550104\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7747473273573157e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7747473273573157e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8348746771410183e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8348746771410183e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6483993578956935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6483993578956935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6404334844550104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6404334844550104\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7747473273573157e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7747473273573157e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8348746771410183e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8348746771410183e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6483993578956935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6483993578956935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6404334844550104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6404334844550104\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7747473273573157e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7747473273573157e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8348746771410183e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8348746771410183e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6483993578956935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6483993578956935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6404334844550104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6404334844550104\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7747473273573157e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7747473273573157e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8348746771410183e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8348746771410183e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6483993578956935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6483993578956935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6404334844550104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6404334844550104\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7747473273573157e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7747473273573157e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8348746771410183e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8348746771410183e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:05:16,051]\u001b[0m Trial 0 finished with value: 0.6569975088769185 and parameters: {'lambda_l1': 1.7747473273573157e-06, 'lambda_l2': 1.8348746771410183e-08, 'num_leaves': 133, 'feature_fraction': 0.6483993578956935, 'bagging_fraction': 0.6404334844550104, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 0 with value: 0.6569975088769185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:08:28,963]\u001b[0m Trial 1 finished with value: 0.680352713188585 and parameters: {'lambda_l1': 1.5500227471617577e-07, 'lambda_l2': 0.018433780898542865, 'num_leaves': 91, 'feature_fraction': 0.889564291608139, 'bagging_fraction': 0.43355649835118754, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 1 with value: 0.680352713188585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7287594166181555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7287594166181555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517604150760278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7517604150760278\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018720624497429878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018720624497429878\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40883920798727896, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40883920798727896\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7287594166181555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7287594166181555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517604150760278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7517604150760278\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018720624497429878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018720624497429878\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40883920798727896, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40883920798727896\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7287594166181555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7287594166181555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517604150760278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7517604150760278\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018720624497429878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018720624497429878\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40883920798727896, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40883920798727896\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7287594166181555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7287594166181555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517604150760278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7517604150760278\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018720624497429878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018720624497429878\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40883920798727896, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40883920798727896\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7287594166181555, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7287594166181555\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7517604150760278, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7517604150760278\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018720624497429878, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018720624497429878\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40883920798727896, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40883920798727896\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:12:02,417]\u001b[0m Trial 2 finished with value: 0.6697023989778538 and parameters: {'lambda_l1': 0.00018720624497429878, 'lambda_l2': 0.40883920798727896, 'num_leaves': 221, 'feature_fraction': 0.7287594166181555, 'bagging_fraction': 0.7517604150760278, 'bagging_freq': 3, 'min_child_samples': 78}. Best is trial 1 with value: 0.680352713188585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17min 37s\n",
      "Wall time: 10min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5070cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 1.5500227471617577e-07, 'lambda_l2': 0.018433780898542865, 'num_leaves': 91, 'feature_fraction': 0.889564291608139, 'bagging_fraction': 0.43355649835118754, 'bagging_freq': 3, 'min_child_samples': 64}\n",
      "0.680352713188585\n"
     ]
    }
   ],
   "source": [
    "print(study.best_trial.params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d26e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = vectorizer.fit_transform(train['text'])\n",
    "features_valid= vectorizer.transform(valid['text'])\n",
    "features_test= vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56b786b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.889564291608139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.889564291608139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43355649835118754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43355649835118754\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5500227471617577e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5500227471617577e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.018433780898542865, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.018433780898542865\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "CPU times: total: 1min 37s\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LGBMClassifier(**study.best_params, random_state=22).fit(features_train, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06932fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b355472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидационной выборке: 0.7603\n"
     ]
    }
   ],
   "source": [
    "print('F1 на валидационной выборке:', np.round(f1_score(valid['toxic'], pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0e1f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ddfad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.7732\n"
     ]
    }
   ],
   "source": [
    "print('F1 на тестовой выборке:', np.round(f1_score(test['toxic'], pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1727f63",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4f27584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1 дефолтной модели</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.7381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.6414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  F1 дефолтной модели\n",
       "0  LogisticRegression               0.7381\n",
       "1       SGDClassifier               0.6414\n",
       "2      LGBMClassifier               0.7505"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model' : ['LogisticRegression', \n",
    "                                  'SGDClassifier', \n",
    "                                  'LGBMClassifier' \n",
    "                                 ],\n",
    "                       'F1 дефолтной модели' : [round(lr_f1, 4) , \n",
    "                                                round(sgdc_f1, 4),\n",
    "                                                round(lgb_f1, 4)\n",
    "                                               ]\n",
    "                      })\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74d2c6",
   "metadata": {},
   "source": [
    "***Из таблицы видно, что без подбора параметров, лучше всех на валидационой выборке себя показывает LGBMClassifier. Для модели были подобраны гиперпараметры и произведена проверка на тесте***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb61d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 LGBMClassifier c подобранными гиперпараметрами на тестовой выборке: 0.7732\n"
     ]
    }
   ],
   "source": [
    "print('F1 LGBMClassifier c подобранными гиперпараметрами на тестовой выборке:', np.round(f1_score(test['toxic'], pred), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b959f",
   "metadata": {},
   "source": [
    "### Сравним модель с константной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e853a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyClassifier(random_state=22, strategy='stratified').fit(features_train, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aae8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_pred_v = dm.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd360449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_pred_v_f1 = f1_score(valid['toxic'], dm_pred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91edbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_pred_t = dm.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbc2c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_pred_t_f1 = f1_score(test['toxic'], dm_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cb25e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Константной модели на валидационной выборке: 0.0853\n",
      " \n",
      "F1 Константной модели на тестовой выборке: 0.1014\n"
     ]
    }
   ],
   "source": [
    "print('F1 Константной модели на валидационной выборке:', np.round(f1_score(valid['toxic'], dm_pred_v), 4))\n",
    "print(' ')\n",
    "print('F1 Константной модели на тестовой выборке:', np.round(f1_score(test['toxic'], dm_pred_t), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8042d89c",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "1. Нам нужно было построить модель, которая будет классифицировать комментарии на позитивные и негативные\n",
    "2. На старте у нас был датасет, в котором было 160 тыс. строк и 3 столбца. Один столбец мы удалили, т к он не нёс никакой информации. Обнаружили, что у нас дисбалас классов с разницей в 10 раз.\n",
    "3. Произвели предобрабтку текстовой информации, чтобы данные можно было подавать в модель.\n",
    "4. Были обучены разные модели. По результатам лучше всего себя показал LGBMClassifier. Для него были подобраны гиперпараметры и произведена проверка на тесте, f1 вышла 0.78, что удовлетворяет наш критерий.\n",
    "5. Значение метрики RMSE DummyClassifier 0.10, это говорит нам о том, что наша обученная модель адекватная"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd230f",
   "metadata": {},
   "source": [
    "## (Дополнительно) Сделаем выборку сбалансированнее и посмотрим что будет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf8bbb",
   "metadata": {},
   "source": [
    "**Увеличиваем число \"токсичных\" в 5 раз** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3df58",
   "metadata": {},
   "source": [
    "### Напишем функцию для увеличения числа токсичных комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8461cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=22)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8184810",
   "metadata": {},
   "source": [
    "### Получим наши фичи и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2bdc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(train['text'], train['toxic'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf45178",
   "metadata": {},
   "source": [
    "### Проверим баланс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10f6ef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100104\n",
       "1     57000\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96531ce5",
   "metadata": {},
   "source": [
    "### Готовим данные для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "426bfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriz = TfidfVectorizer(tokenizer=lambda x: change_word(clear_text(x, remove_stop_words=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3eecd9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 35s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = vectoriz.fit_transform(features_upsampled)\n",
    "X_valid = vectoriz.transform(valid['text'])\n",
    "X_test = vectoriz.transform(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a04360",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6734a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_up = LogisticRegression(solver='lbfgs', random_state=22).fit(X_train, target_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f3daf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_up_pred = lr_up.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b94677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_up_f1 = f1_score(valid['toxic'], lr_up_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "314c8629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736226091921211"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_up_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56993d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     30553\n",
      "           1       0.75      0.80      0.77      3376\n",
      "\n",
      "    accuracy                           0.95     33929\n",
      "   macro avg       0.86      0.89      0.87     33929\n",
      "weighted avg       0.95      0.95      0.95     33929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(valid['toxic'], lr_up_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89a5fb",
   "metadata": {},
   "source": [
    "***Чуть поднялась f1, после снижения дисбаланса***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d14fb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_up(trial):\n",
    "    classifier_up = Pipeline(steps=[(\"classifier\",LGBMClassifier(random_state=22))])\n",
    "\n",
    "    params = {\n",
    "        'classifier__lambda_l1': trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        'classifier__lambda_l2': trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        'classifier__num_leaves': trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        'classifier__feature_fraction': trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        'classifier__bagging_fraction': trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        'classifier__bagging_freq': trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        'classifier__min_child_samples': trial.suggest_int(\"min_child_samples\", 5, 100)\n",
    "    }\n",
    "\n",
    "    classifier_up.set_params(**params)\n",
    "\n",
    "    classifier_up.fit(X_train, target_upsampled)\n",
    "\n",
    "    f1_up = cross_val_score(classifier_up, X_valid, valid['toxic'], cv=5, scoring='f1')\n",
    "\n",
    "    return  f1_up.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3121c51d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:15:36,977]\u001b[0m A new study created in memory with name: no-name-e5c2523b-1701-4919-a537-6833a6a7936d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:17:53,977]\u001b[0m Trial 0 finished with value: 0.7428887227225556 and parameters: {'lambda_l1': 0.13575868964275786, 'lambda_l2': 0.020382338887404823, 'num_leaves': 73, 'feature_fraction': 0.4576915231589659, 'bagging_fraction': 0.8018869667515953, 'bagging_freq': 7, 'min_child_samples': 7}. Best is trial 0 with value: 0.7428887227225556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9071263563803612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071263563803612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917022474975702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917022474975702\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.837652123943285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.837652123943285\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0095490458985948e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0095490458985948e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9071263563803612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071263563803612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917022474975702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917022474975702\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.837652123943285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.837652123943285\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0095490458985948e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0095490458985948e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9071263563803612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071263563803612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917022474975702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917022474975702\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.837652123943285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.837652123943285\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0095490458985948e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0095490458985948e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9071263563803612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071263563803612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917022474975702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917022474975702\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.837652123943285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.837652123943285\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0095490458985948e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0095490458985948e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9071263563803612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071263563803612\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9917022474975702, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9917022474975702\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.837652123943285, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.837652123943285\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0095490458985948e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0095490458985948e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:19:46,114]\u001b[0m Trial 1 finished with value: 0.6787032573236719 and parameters: {'lambda_l1': 0.837652123943285, 'lambda_l2': 2.0095490458985948e-08, 'num_leaves': 120, 'feature_fraction': 0.9071263563803612, 'bagging_fraction': 0.9917022474975702, 'bagging_freq': 5, 'min_child_samples': 75}. Best is trial 0 with value: 0.7428887227225556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5676248069127506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5676248069127506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44842668864085605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44842668864085605\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3731730354514595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3731730354514595\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008239018292013082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008239018292013082\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5676248069127506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5676248069127506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44842668864085605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44842668864085605\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3731730354514595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3731730354514595\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008239018292013082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008239018292013082\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5676248069127506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5676248069127506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44842668864085605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44842668864085605\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3731730354514595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3731730354514595\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008239018292013082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008239018292013082\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5676248069127506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5676248069127506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44842668864085605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44842668864085605\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3731730354514595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3731730354514595\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008239018292013082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008239018292013082\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5676248069127506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5676248069127506\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44842668864085605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44842668864085605\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3731730354514595, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3731730354514595\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008239018292013082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008239018292013082\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-20 21:21:02,771]\u001b[0m Trial 2 finished with value: 0.6925469582133431 and parameters: {'lambda_l1': 2.3731730354514595, 'lambda_l2': 0.0008239018292013082, 'num_leaves': 123, 'feature_fraction': 0.5676248069127506, 'bagging_fraction': 0.44842668864085605, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 0 with value: 0.7428887227225556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17min 18s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_up, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25eae004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 0.13575868964275786, 'lambda_l2': 0.020382338887404823, 'num_leaves': 73, 'feature_fraction': 0.4576915231589659, 'bagging_fraction': 0.8018869667515953, 'bagging_freq': 7, 'min_child_samples': 7}\n",
      "0.7428887227225556\n"
     ]
    }
   ],
   "source": [
    "print(study.best_trial.params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aeb425b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4576915231589659, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4576915231589659\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8018869667515953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8018869667515953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13575868964275786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13575868964275786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.020382338887404823, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020382338887404823\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(**study.best_params, random_state=22).fit(X_train, target_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a23ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_up_v = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a41a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на валидационной выборке: 0.7762\n"
     ]
    }
   ],
   "source": [
    "print('F1 на валидационной выборке:', np.round(f1_score(valid['toxic'], pred_up_v), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e29aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_up_t = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b95d001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.7845\n"
     ]
    }
   ],
   "source": [
    "print('F1 на тестовой выборке:', np.round(f1_score(test['toxic'], pred_up_t), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f49a1b",
   "metadata": {},
   "source": [
    "**Ну а для бустинга ничего не поменялось**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
